{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed15cfa0fa7a42ae",
   "metadata": {},
   "source": "# RNA-seq Data Analysis Pipeline Tutorial\n### FastQC / MultiQC → STAR → featureCounts → TPM → DESeq2 → Pathway/GSEA → Gene Network → TF Binding\n\n---\n\n| Step | Tool | Purpose |\n|------|------|---------|\n| 1 | FastQC / MultiQC | Raw read quality control |\n| 2 | STAR (2-pass) | Splice-aware genome alignment |\n| 3 | featureCounts | Gene-level read quantification |\n| 4 | TPM | Library-size + length normalization |\n| 5 | pyDESeq2 | Differential expression testing |\n| 6 | gseapy (Enrichr) | Over-representation analysis (ORA) |\n| 7 | gseapy (Prerank) | Gene set enrichment analysis (GSEA) |\n| 8 | STRING + networkx | Gene–gene interaction network |\n| 9 | ChEA3 + decoupler | Transcription factor binding prediction |\n\n**Input :** `data/raw_counts.csv`, `data/gene_lengths.csv`, `data/metadata.csv`\n**Output:** `results/tables/` (DE results) and `results/figures/` (all plots)\n\n> **Tutorial mode:** Section 3 simulates a realistic RNA-seq dataset so every cell\n> runs end-to-end without real FASTQ files. Replace the simulated data with your\n> own `raw_counts.csv` / `gene_lengths.csv` to analyse real data."
  },
  {
   "cell_type": "markdown",
   "id": "79fff3ad03054c21",
   "metadata": {},
   "source": "## 0. Install & Import Dependencies"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe2db213c8242c6",
   "metadata": {},
   "outputs": [],
   "source": "# Run this cell once to install required packages\nimport subprocess, sys\n\npkgs = [\n    \"pydeseq2\", \"gseapy\", \"networkx\", \"decoupler\",\n    \"matplotlib\", \"seaborn\", \"pandas\", \"numpy\", \"scipy\",\n    \"scikit-learn\", \"adjustText\", \"requests\",\n]\nfor p in pkgs:\n    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", p, \"-q\"],\n                          stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\nprint(\"All packages installed.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e46ae5424fc44d8",
   "metadata": {},
   "outputs": [],
   "source": "import warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport os, json, itertools\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches\nimport matplotlib.gridspec as gridspec\nimport seaborn as sns\nfrom scipy import stats\nfrom scipy.stats import zscore\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nimport networkx as nx\nimport requests\n\n# ── Plotting defaults ─────────────────────────────────────────────────────────\nplt.rcParams.update({\n    \"figure.dpi\": 150,\n    \"font.family\": \"DejaVu Sans\",\n    \"font.size\": 10,\n    \"axes.spines.top\": False,\n    \"axes.spines.right\": False,\n    \"pdf.fonttype\": 42,\n})\nsns.set_style(\"white\")\nsns.set_context(\"notebook\")\n\nCOND_COLORS = {\"Control\": \"#4C72B0\", \"Treatment\": \"#DD8452\"}\n\n# ── Output directories ────────────────────────────────────────────────────────\nfor d in [\"data\", \"results/figures\", \"results/tables\"]:\n    os.makedirs(d, exist_ok=True)\n\nprint(\"Setup complete.\")"
  },
  {
   "cell_type": "markdown",
   "id": "49c4440a25e14950",
   "metadata": {},
   "source": "## 1. Sample Metadata\n\nThe metadata CSV maps each sample to its experimental condition and covariates.\nEvery downstream step uses this file to label plots and define contrasts."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723b415614594dd2",
   "metadata": {},
   "outputs": [],
   "source": "# ── Create / load metadata ────────────────────────────────────────────────────\nmeta_path = \"data/metadata.csv\"\n\nif not os.path.exists(meta_path):\n    metadata = pd.DataFrame({\n        \"sample_id\" : [\"ctrl_1\",\"ctrl_2\",\"ctrl_3\",\"ctrl_4\",\n                        \"trt_1\", \"trt_2\", \"trt_3\", \"trt_4\"],\n        \"condition\" : [\"Control\"]*4 + [\"Treatment\"]*4,\n        \"batch\"     : [\"A\",\"A\",\"B\",\"B\",\"A\",\"A\",\"B\",\"B\"],\n        \"sex\"       : [\"M\",\"F\",\"M\",\"F\",\"M\",\"F\",\"M\",\"F\"],\n    })\n    metadata.set_index(\"sample_id\", inplace=True)\n    metadata.to_csv(meta_path)\nelse:\n    metadata = pd.read_csv(meta_path, index_col=0)\n\nSAMPLES    = metadata.index.tolist()\nN_SAMPLES  = len(SAMPLES)\n\nprint(f\"Metadata loaded: {N_SAMPLES} samples\")\nprint(metadata.to_string())"
  },
  {
   "cell_type": "markdown",
   "id": "7819cb64af2d4d56",
   "metadata": {},
   "source": "## 2. Upstream Processing (Shell)\n\n> **Skip if you already have `data/raw_counts.csv` and `data/gene_lengths.csv`.**\n> The full shell pipeline is in `scripts/upstream_processing.sh`.\n\nThe cells below illustrate the key commands; run them in a terminal or Jupyter\n`%%bash` cells after installing the required bioinformatics tools.\n\n### 2.1 Quality Control — FastQC / MultiQC\n```bash\n# Per-sample FastQC\nfastqc data/fastq/*.fastq.gz --outdir results/qc/fastqc_raw --threads 8\n\n# Aggregate report\nmultiqc results/qc/fastqc_raw --outdir results/qc --filename multiqc_raw\n```\n\n### 2.2 Splice-Aware Alignment — STAR (2-pass)\n```bash\n# Build genome index (once)\nSTAR --runMode genomeGenerate \\\n     --genomeDir genome/STAR_index \\\n     --genomeFastaFiles genome/genome.fa \\\n     --sjdbGTFfile genome/annotation.gtf \\\n     --sjdbOverhang 149 --runThreadN 8\n\n# Align each sample\nSTAR --runThreadN 8 \\\n     --genomeDir genome/STAR_index \\\n     --readFilesIn data/fastq/ctrl_1_R1.fastq.gz data/fastq/ctrl_1_R2.fastq.gz \\\n     --readFilesCommand zcat \\\n     --outSAMtype BAM SortedByCoordinate \\\n     --quantMode GeneCounts \\\n     --outFileNamePrefix results/aligned/ctrl_1/\nsamtools index results/aligned/ctrl_1/Aligned.sortedByCoord.out.bam\n```\n\n### 2.3 Gene-Level Quantification — featureCounts\n```bash\nfeatureCounts -T 8 -p --countReadPairs -s 2 -B -C \\\n    -a genome/annotation.gtf \\\n    -o results/counts/featureCounts_raw.txt \\\n    results/aligned/*/Aligned.sortedByCoord.out.bam\n```\n\n**Key flag:** `-s 2` = reverse-stranded (dUTP/TruSeq kits).\nUse `infer_experiment.py` (RSeQC) to verify strandedness before counting."
  },
  {
   "cell_type": "markdown",
   "id": "6b7b923543454a75",
   "metadata": {},
   "source": "## 3. Simulate Tutorial Dataset\n\nWe generate a realistic negative-binomial RNA-seq count matrix so every\ndownstream cell executes without real FASTQ files.\n\n**Design:** 4 Control vs 4 Treatment samples, ~15 000 genes,\n~160 true up-regulated DEGs (immune/apoptosis) and ~100 true down-regulated DEGs\n(cell cycle/proliferation), remainder background."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8079627f114676",
   "metadata": {},
   "outputs": [],
   "source": "np.random.seed(42)\n\n# ── True DEG lists — real HGNC symbols for meaningful pathway/TF results ──────\nUP_GENES = [\n    # Interferon / antiviral\n    \"IFNG\",\"STAT1\",\"STAT2\",\"IRF1\",\"IRF3\",\"IRF7\",\"IRF9\",\n    \"ISG15\",\"ISG20\",\"MX1\",\"MX2\",\"OAS1\",\"OAS2\",\"OAS3\",\"OASL\",\n    \"IFIT1\",\"IFIT2\",\"IFIT3\",\"IFIT5\",\"IFITM1\",\"IFITM2\",\"IFITM3\",\n    \"RSAD2\",\"HERC5\",\"HERC6\",\"USP18\",\"TRIM25\",\"DDX58\",\"IFIH1\",\n    # Cytokines / chemokines\n    \"IL6\",\"IL1A\",\"IL1B\",\"IL12A\",\"IL12B\",\"IL15\",\"IL18\",\n    \"TNF\",\"TNFSF10\",\"IFNB1\",\"CXCL9\",\"CXCL10\",\"CXCL11\",\n    \"CCL2\",\"CCL5\",\"CCL7\",\"CXCL8\",\n    # NF-κB pathway\n    \"NFKB1\",\"NFKB2\",\"RELA\",\"RELB\",\"REL\",\"NFKBIA\",\"NFKBIZ\",\n    \"TLR3\",\"TLR4\",\"TLR7\",\"MYD88\",\"TICAM1\",\"RIPK1\",\n    # Apoptosis / p53\n    \"TP53\",\"BAX\",\"BAK1\",\"BBC3\",\"PMAIP1\",\"BID\",\"CYCS\",\"APAF1\",\n    \"CASP3\",\"CASP8\",\"CASP9\",\"CASP7\",\"FAS\",\"FASLG\",\n    \"CDKN1A\",\"GADD45A\",\"GADD45B\",\"MDM2\",\n    # Cytotoxic T-cell / NK markers\n    \"CD8A\",\"GZMB\",\"GZMK\",\"PRF1\",\"GNLY\",\"NKG7\",\"CD274\",\n    \"PDCD1\",\"HAVCR2\",\"LAG3\",\"TIGIT\",\n]\n\nDOWN_GENES = [\n    # Cell cycle — CDKs / Cyclins\n    \"CDK1\",\"CDK2\",\"CDK4\",\"CDK6\",\n    \"CCNA2\",\"CCNB1\",\"CCNB2\",\"CCND1\",\"CCND2\",\"CCNE1\",\"CCNE2\",\n    \"E2F1\",\"E2F2\",\"E2F3\",\"MYBL2\",\n    # Replication / proliferation markers\n    \"MKI67\",\"PCNA\",\"MCM2\",\"MCM4\",\"MCM7\",\"GINS1\",\"CDC45\",\n    \"RRM1\",\"RRM2\",\"TYMS\",\"DHFR\",\"TK1\",\n    # Mitosis regulators\n    \"AURKB\",\"AURKA\",\"PLK1\",\"PLK4\",\"BUB1\",\"BUB1B\",\n    \"MAD2L1\",\"CDC20\",\"CDH1\",\"TOP2A\",\"PTTG1\",\n    \"CENPE\",\"CENPF\",\"KIF11\",\"KIF20A\",\"RACGAP1\",\"PRC1\",\"BIRC5\",\n    # Pro-survival / anti-apoptosis\n    \"BCL2\",\"BCL2L1\",\"MCL1\",\"XIAP\",\"BIRC3\",\n    # PI3K / AKT / mTOR\n    \"AKT1\",\"AKT2\",\"AKT3\",\"PIK3CA\",\"PIK3CB\",\n    \"MTOR\",\"RPS6KB1\",\"EIF4EBP1\",\n    # MYC targets / ribosome biogenesis\n    \"MYC\",\"MYCN\",\"NPM1\",\"NCL\",\"TERT\",\"NME1\",\n    # Warburg / hypoxia metabolism\n    \"LDHA\",\"PKM\",\"HK2\",\"GPI\",\"PFKL\",\"ALDOA\",\"ENO1\",\n    \"SLC2A1\",\"VEGFA\",\"CA9\",\"HIF1A\",\n]\n\n# Remove any overlap\nDOWN_GENES = [g for g in DOWN_GENES if g not in UP_GENES]\n\nALL_DEG  = list(dict.fromkeys(UP_GENES + DOWN_GENES))\nBG_GENES = [f\"ENSG{i:011d}\" for i in range(1, 14601)]\nALL_GENES = ALL_DEG + BG_GENES\nN_GENES  = len(ALL_GENES)\n\nprint(f\"Up-regulated true DEGs  : {len(UP_GENES)}\")\nprint(f\"Down-regulated true DEGs: {len(DOWN_GENES)}\")\nprint(f\"Background genes        : {len(BG_GENES):,}\")\nprint(f\"Total genes             : {N_GENES:,}\")\nprint(f\"Total samples           : {N_SAMPLES}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b505aeb322d4175",
   "metadata": {},
   "outputs": [],
   "source": "# ── Negative-binomial count simulation ────────────────────────────────────────\nprint(\"Simulating count matrix …\")\n\n# Mean expression in Control (log-normal → realistic range)\nbase_mean = np.random.lognormal(mean=3.8, sigma=2.0, size=N_GENES).clip(0.5, 8000)\n\n# Per-sample library-size factors\nlib_factors = np.array([1.15, 0.90, 1.05, 0.92, 1.20, 0.85, 0.98, 1.10])\n\n# Per-gene dispersion  (larger dispersion = noisier)\ndispersion = np.random.exponential(scale=0.15, size=N_GENES).clip(0.01, 2.0)\n\n# Simulate gene lengths (bp) — log-normal, clipped to realistic range\ngene_lengths_bp = np.random.lognormal(mean=7.5, sigma=1.0, size=N_GENES).astype(int)\ngene_lengths_bp = np.clip(gene_lengths_bp, 200, 100_000)\n\ncounts_mat = np.zeros((N_GENES, N_SAMPLES), dtype=np.int32)\n\nfor i, gene in enumerate(ALL_GENES):\n    mu_ctrl = base_mean[i]\n    mu_trt  = mu_ctrl\n\n    if gene in UP_GENES:\n        lfc = np.random.uniform(1.0, 3.5)\n        mu_trt = mu_ctrl * (2 ** lfc)\n    elif gene in DOWN_GENES:\n        lfc = np.random.uniform(1.0, 3.5)\n        mu_trt = mu_ctrl / (2 ** lfc)\n\n    for j in range(N_SAMPLES):\n        mu = (mu_ctrl if j < 4 else mu_trt) * lib_factors[j]\n        d  = dispersion[i]\n        r  = max(1.0 / d, 0.05)\n        p  = r / (r + mu)\n        p  = np.clip(p, 1e-8, 1 - 1e-8)\n        counts_mat[i, j] = np.random.negative_binomial(r, p)\n\n# ── DataFrames ────────────────────────────────────────────────────────────────\ncounts_df = pd.DataFrame(counts_mat, index=ALL_GENES, columns=SAMPLES)\ncounts_df.index.name = \"gene_id\"\n\ngene_lengths = pd.Series(gene_lengths_bp, index=ALL_GENES, name=\"length\")\ngene_lengths.index.name = \"gene_id\"\n\n# Save\ncounts_df.to_csv(\"data/raw_counts.csv\")\ngene_lengths.to_csv(\"data/gene_lengths.csv\", header=True)\n\nprint(f\"Saved: data/raw_counts.csv  ({counts_df.shape[0]:,} genes × {counts_df.shape[1]} samples)\")\nprint(f\"Saved: data/gene_lengths.csv\")\nprint(f\"Library sizes: {counts_df.sum().min()/1e6:.1f}M – {counts_df.sum().max()/1e6:.1f}M reads\")"
  },
  {
   "cell_type": "markdown",
   "id": "ae2a7a95165d4b20",
   "metadata": {},
   "source": "## 4. Load Count Matrix\n\n```python\n# To use your own data, replace the simulated files:\n#   data/raw_counts.csv   — gene_id × sample matrix of integer counts\n#   data/gene_lengths.csv — gene_id, length (bp)  [from featureCounts column 5]\n#   data/metadata.csv     — sample_id, condition, [batch, ...]\n```"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511391b31a674366",
   "metadata": {},
   "outputs": [],
   "source": "counts_df     = pd.read_csv(\"data/raw_counts.csv\",   index_col=0)\ngene_lengths  = pd.read_csv(\"data/gene_lengths.csv\", index_col=0).squeeze()\nmetadata      = pd.read_csv(\"data/metadata.csv\",     index_col=0)\n\n# Align sample order\ncounts_df = counts_df[metadata.index]\n\nprint(\"Count matrix :\", counts_df.shape)\nprint(\"Gene lengths :\", gene_lengths.shape)\nprint(\"Metadata     :\", metadata.shape)\nprint()\ndisplay(counts_df.iloc[:5, :])"
  },
  {
   "cell_type": "markdown",
   "id": "0724d9d50bd74dca",
   "metadata": {},
   "source": "## 5. Count-Level Quality Control\n\nCheck three indicators before normalisation:\n1. **Library sizes** — total mapped reads per sample\n2. **Genes detected** — number of genes with count > 0\n3. **Sample correlation** — are replicates more similar than cross-condition pairs?"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8a0f1e1deb487f",
   "metadata": {},
   "outputs": [],
   "source": "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n\nsample_colors = [COND_COLORS[metadata.loc[s, \"condition\"]] for s in SAMPLES]\n\n# 1. Library sizes\nlib_sizes = counts_df.sum() / 1e6\naxes[0].bar(SAMPLES, lib_sizes, color=sample_colors, edgecolor=\"white\", linewidth=0.5)\naxes[0].axhline(lib_sizes.mean(), color=\"red\", ls=\"--\", alpha=0.7,\n                label=f\"Mean {lib_sizes.mean():.1f} M\")\naxes[0].set_ylabel(\"Mapped reads (millions)\")\naxes[0].set_title(\"Library Sizes\", fontweight=\"bold\")\naxes[0].tick_params(axis=\"x\", rotation=45)\naxes[0].legend(fontsize=9)\n\n# 2. Genes detected\ndetected = (counts_df > 0).sum()\naxes[1].bar(SAMPLES, detected, color=sample_colors, edgecolor=\"white\", linewidth=0.5)\naxes[1].set_ylabel(\"Genes detected (count > 0)\")\naxes[1].set_title(\"Gene Detection\", fontweight=\"bold\")\naxes[1].tick_params(axis=\"x\", rotation=45)\n\n# 3. Sample correlation (log2 counts)\nlog_raw = np.log2(counts_df + 1)\ncorr    = log_raw.corr()\nsns.heatmap(corr, ax=axes[2], cmap=\"RdYlBu_r\", vmin=0.85, vmax=1.0,\n            annot=True, fmt=\".3f\", annot_kws={\"size\": 8},\n            square=True, cbar_kws={\"shrink\": 0.8},\n            xticklabels=SAMPLES, yticklabels=SAMPLES)\naxes[2].set_title(\"Sample Pearson Correlation\n(log₂ counts)\", fontweight=\"bold\")\naxes[2].tick_params(axis=\"x\", rotation=45)\naxes[2].tick_params(axis=\"y\", rotation=0)\n\n# Legend\nfor ax in axes[:2]:\n    ax.legend(handles=[\n        mpatches.Patch(color=COND_COLORS[\"Control\"],   label=\"Control\"),\n        mpatches.Patch(color=COND_COLORS[\"Treatment\"], label=\"Treatment\"),\n    ], fontsize=9)\n\nplt.tight_layout()\nplt.savefig(\"results/figures/01_qc_summary.pdf\", bbox_inches=\"tight\")\nplt.savefig(\"results/figures/01_qc_summary.png\", bbox_inches=\"tight\", dpi=300)\nplt.show()\nprint(\"Saved → results/figures/01_qc_summary.pdf/.png\")"
  },
  {
   "cell_type": "markdown",
   "id": "fad6f84731b24998",
   "metadata": {},
   "source": "## 6. TPM Normalization\n\n**TPM (Transcripts Per Million)** normalises for:\n1. **Gene length** — longer genes accumulate more fragments\n2. **Sequencing depth** — samples with more total reads give larger raw counts\n\n$$\\text{TPM}_i = \\frac{X_i / L_i}{\\sum_j X_j / L_j} \\times 10^6$$\n\nTPM is suitable for visualisation and within-study comparisons.\nDifferential expression uses raw counts via DESeq2's own normalisation."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998edb4339e749a5",
   "metadata": {},
   "outputs": [],
   "source": "def compute_tpm(counts: pd.DataFrame, lengths_bp: pd.Series) -> pd.DataFrame:\n    \"\"\"\n    Compute TPM.\n\n    Parameters\n    ----------\n    counts     : genes × samples DataFrame of integer raw counts\n    lengths_bp : per-gene effective length in base pairs (e.g. from featureCounts)\n\n    Returns\n    -------\n    genes × samples DataFrame of TPM values\n    \"\"\"\n    lengths_kb = lengths_bp.reindex(counts.index) / 1_000          # bp → kb\n    rpk        = counts.div(lengths_kb, axis=0)                    # reads per kb\n    scale      = rpk.sum(axis=0) / 1e6                             # per-million factor\n    tpm        = rpk.div(scale, axis=1)\n    return tpm\n\n\ntpm_df = compute_tpm(counts_df, gene_lengths)\n\n# Filter lowly expressed genes: keep genes with TPM ≥ 1 in ≥ min_samples\nMIN_TPM      = 1.0\nMIN_SAMPLES  = 2\nkeep         = (tpm_df >= MIN_TPM).sum(axis=1) >= MIN_SAMPLES\ntpm_filt     = tpm_df.loc[keep].copy()\ncounts_filt  = counts_df.loc[keep].copy()\n\n# Log2-TPM for visualisation\nlog2_tpm = np.log2(tpm_filt + 1)\n\nprint(f\"Genes before filtering : {counts_df.shape[0]:,}\")\nprint(f\"Genes after  filtering : {counts_filt.shape[0]:,}  \"\n      f\"(TPM ≥ {MIN_TPM} in ≥ {MIN_SAMPLES} samples)\")\nprint()\nprint(\"TPM summary (filtered):\")\nprint(tpm_filt.describe().round(1).to_string())"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9541c6ec79646dd",
   "metadata": {},
   "outputs": [],
   "source": "# Distribution plots: raw log2-counts vs log2-TPM\nfig, axes = plt.subplots(1, 2, figsize=(13, 5))\n\nfor j, sample in enumerate(SAMPLES):\n    c = COND_COLORS[metadata.loc[sample, \"condition\"]]\n\n    raw_vals = np.log2(counts_filt[sample] + 1)\n    raw_vals = raw_vals[raw_vals > 0]\n    axes[0].hist(raw_vals, bins=60, density=True, alpha=0.35, color=c,\n                 histtype=\"stepfilled\", linewidth=0)\n\n    tpm_vals = np.log2(tpm_filt[sample] + 1)\n    tpm_vals = tpm_vals[tpm_vals > 0]\n    axes[1].hist(tpm_vals, bins=60, density=True, alpha=0.35, color=c,\n                 histtype=\"stepfilled\", linewidth=0)\n\nfor ax, title, xlabel in zip(\n    axes,\n    [\"Raw Counts (log₂ + 1)\", \"TPM Normalised (log₂ + 1)\"],\n    [\"log₂(count + 1)\",        \"log₂(TPM + 1)\"],\n):\n    ax.set_xlabel(xlabel); ax.set_ylabel(\"Density\"); ax.set_title(title, fontweight=\"bold\")\n    ax.legend(handles=[\n        mpatches.Patch(color=COND_COLORS[\"Control\"],   alpha=0.6, label=\"Control\"),\n        mpatches.Patch(color=COND_COLORS[\"Treatment\"], alpha=0.6, label=\"Treatment\"),\n    ], fontsize=9)\n\nplt.tight_layout()\nplt.savefig(\"results/figures/02_normalization.pdf\", bbox_inches=\"tight\")\nplt.savefig(\"results/figures/02_normalization.png\", bbox_inches=\"tight\", dpi=300)\nplt.show()\nprint(\"Saved → results/figures/02_normalization.pdf/.png\")"
  },
  {
   "cell_type": "markdown",
   "id": "39f2bf8e3ea84ff4",
   "metadata": {},
   "source": "## 7. Principal Component Analysis (PCA)\n\nPCA reveals global structure: replicates should cluster together and conditions\nshould separate along the first principal component if there is a transcriptional\nresponse."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db999c7552ef4a33",
   "metadata": {},
   "outputs": [],
   "source": "# Prepare matrix: samples × genes, z-scored per gene\nX_mat    = log2_tpm.T.values                          # (8, n_genes)\nscaler   = StandardScaler()\nX_scaled = scaler.fit_transform(X_mat)\n\npca         = PCA(n_components=min(N_SAMPLES, 8))\npca_coords  = pca.fit_transform(X_scaled)\nvar_exp     = pca.explained_variance_ratio_ * 100\n\npca_df = pd.DataFrame(pca_coords[:, :4], index=SAMPLES,\n                       columns=[f\"PC{i+1}\" for i in range(4)])\npca_df = pca_df.join(metadata[[\"condition\", \"batch\"]])\n\nprint(\"Variance explained by top PCs:\")\nfor i, v in enumerate(var_exp[:5]):\n    print(f\"  PC{i+1}: {v:.1f}%\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6f00f4f5af4616",
   "metadata": {},
   "outputs": [],
   "source": "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n\n# ── PC1 vs PC2 coloured by condition ────────────────────────────────────────\nfor cond, grp in pca_df.groupby(\"condition\"):\n    axes[0].scatter(grp[\"PC1\"], grp[\"PC2\"],\n                    c=COND_COLORS[cond], s=130, edgecolors=\"white\",\n                    linewidth=1.5, zorder=5, label=cond, alpha=0.9)\nfor idx, row in pca_df.iterrows():\n    axes[0].annotate(idx, (row[\"PC1\"], row[\"PC2\"]),\n                     fontsize=8, ha=\"left\", xytext=(5, 4),\n                     textcoords=\"offset points\")\naxes[0].set_xlabel(f\"PC1 ({var_exp[0]:.1f}%)\")\naxes[0].set_ylabel(f\"PC2 ({var_exp[1]:.1f}%)\")\naxes[0].set_title(\"PCA — Condition\", fontweight=\"bold\")\naxes[0].legend(fontsize=10)\nfor ax in axes[:2]:\n    ax.axhline(0, color=\"gray\", ls=\"--\", alpha=0.4, lw=0.8)\n    ax.axvline(0, color=\"gray\", ls=\"--\", alpha=0.4, lw=0.8)\n\n# ── PC1 vs PC2 coloured by batch ─────────────────────────────────────────────\nbatch_pal = {\"A\": \"#2ca02c\", \"B\": \"#d62728\"}\nfor batch, grp in pca_df.groupby(\"batch\"):\n    axes[1].scatter(grp[\"PC1\"], grp[\"PC2\"],\n                    c=batch_pal[batch], s=130,\n                    marker=\"o\" if batch == \"A\" else \"s\",\n                    edgecolors=\"white\", linewidth=1.5,\n                    zorder=5, label=f\"Batch {batch}\", alpha=0.9)\nfor idx, row in pca_df.iterrows():\n    axes[1].annotate(idx, (row[\"PC1\"], row[\"PC2\"]),\n                     fontsize=8, ha=\"left\", xytext=(5, 4),\n                     textcoords=\"offset points\")\naxes[1].set_xlabel(f\"PC1 ({var_exp[0]:.1f}%)\")\naxes[1].set_ylabel(f\"PC2 ({var_exp[1]:.1f}%)\")\naxes[1].set_title(\"PCA — Batch\", fontweight=\"bold\")\naxes[1].legend(fontsize=10)\n\n# ── Scree plot ────────────────────────────────────────────────────────────────\nxs = range(1, len(var_exp) + 1)\naxes[2].bar(xs, var_exp, color=\"steelblue\", edgecolor=\"white\")\naxes[2].plot(xs, var_exp, \"ko-\", markersize=5)\naxes[2].set_xlabel(\"Principal Component\")\naxes[2].set_ylabel(\"Variance Explained (%)\")\naxes[2].set_title(\"Scree Plot\", fontweight=\"bold\")\naxes[2].set_xticks(list(xs))\n\nplt.tight_layout()\nplt.savefig(\"results/figures/03_pca.pdf\", bbox_inches=\"tight\")\nplt.savefig(\"results/figures/03_pca.png\", bbox_inches=\"tight\", dpi=300)\nplt.show()\nprint(\"Saved → results/figures/03_pca.pdf/.png\")"
  },
  {
   "cell_type": "markdown",
   "id": "561c8cbe013d4722",
   "metadata": {},
   "source": "## 8. Differential Expression — DESeq2\n\n**pyDESeq2** is the official Python port of the R DESeq2 package. It uses:\n- Negative-binomial GLM with shrunk dispersion estimates\n- Wald test for contrasts\n- Benjamini–Hochberg FDR correction\n- Cook's distance filtering for outlier counts\n\n> **Contrast:** Treatment vs Control\n> Positive log₂FC = higher expression in Treatment."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e2886cfea64452",
   "metadata": {},
   "outputs": [],
   "source": "try:\n    from pydeseq2.dds import DeseqDataSet\n    from pydeseq2.ds  import DeseqStats\n    HAVE_PYDESEQ2 = True\n    print(\"pyDESeq2 available — running DESeq2 pipeline.\")\nexcept ImportError:\n    HAVE_PYDESEQ2 = False\n    print(\"pyDESeq2 not found.  Install: pip install pydeseq2\")\n    print(\"Falling back to Welch t-test + BH correction.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8e3ec245ef4815",
   "metadata": {},
   "outputs": [],
   "source": "if HAVE_PYDESEQ2:\n    # pyDESeq2 expects counts as (samples × genes), integer dtype\n    counts_deseq = counts_filt.T.astype(int)          # (8, n_filtered_genes)\n    meta_deseq   = metadata[[\"condition\"]].copy()\n    counts_deseq = counts_deseq.loc[meta_deseq.index]\n\n    print(f\"Running DESeq2 on {counts_deseq.shape[1]:,} genes × {counts_deseq.shape[0]} samples …\")\n\n    dds = DeseqDataSet(\n        counts        = counts_deseq,\n        metadata      = meta_deseq,\n        design_factors= \"condition\",\n        refit_cooks   = True,\n        n_cpus        = 4,\n    )\n    dds.deseq2()\n\n    stat_res = DeseqStats(\n        dds,\n        contrast = [\"condition\", \"Treatment\", \"Control\"],\n        alpha    = 0.05,\n        cooks_filter         = True,\n        independent_filter   = True,\n    )\n    stat_res.summary()\n\n    de_results = stat_res.results_df.copy()\n    de_results.index.name = \"gene\"\n    de_results = de_results.reset_index()\n\nelse:\n    # ── Fallback: Welch t-test + BH ──────────────────────────────────────────\n    from statsmodels.stats.multitest import multipletests\n\n    ctrl_s = [s for s in SAMPLES if metadata.loc[s,\"condition\"]==\"Control\"]\n    trt_s  = [s for s in SAMPLES if metadata.loc[s,\"condition\"]==\"Treatment\"]\n    lc     = log2_tpm\n\n    rows = []\n    for gene in lc.index:\n        c, t = lc.loc[gene, ctrl_s].values, lc.loc[gene, trt_s].values\n        lfc  = t.mean() - c.mean()\n        tst, pv = stats.ttest_ind(t, c, equal_var=False)\n        rows.append({\"gene\": gene, \"baseMean\": np.exp2(np.concatenate([c,t])).mean(),\n                     \"log2FoldChange\": lfc, \"stat\": tst, \"pvalue\": pv})\n\n    de_results = pd.DataFrame(rows)\n    _, padj, *_ = multipletests(de_results[\"pvalue\"].fillna(1), method=\"fdr_bh\")\n    de_results[\"padj\"]  = padj\n    de_results[\"lfcSE\"] = np.abs(de_results[\"log2FoldChange\"]) * 0.3\n\nprint(f\"Total genes tested: {len(de_results):,}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40b7f7763894b80",
   "metadata": {},
   "outputs": [],
   "source": "# ── Annotate results ──────────────────────────────────────────────────────────\nLFC_THR  = 1.0   # |log2FC| > 1 = 2-fold\nPADJ_THR = 0.05  # FDR < 5 %\n\nde_results[\"direction\"] = \"Not significant\"\nde_results.loc[\n    (de_results.padj < PADJ_THR) & (de_results.log2FoldChange >  LFC_THR),\n    \"direction\"] = \"Up-regulated\"\nde_results.loc[\n    (de_results.padj < PADJ_THR) & (de_results.log2FoldChange < -LFC_THR),\n    \"direction\"] = \"Down-regulated\"\n\nn_up   = (de_results.direction == \"Up-regulated\").sum()\nn_down = (de_results.direction == \"Down-regulated\").sum()\n\nprint(\"=\" * 50)\nprint(\"  DE Results (Treatment vs Control)\")\nprint(\"=\" * 50)\nprint(f\"  Total tested  : {len(de_results):,}\")\nprint(f\"  Up-regulated  : {n_up:,}  (padj<{PADJ_THR}, log2FC>{LFC_THR})\")\nprint(f\"  Down-regulated: {n_down:,}  (padj<{PADJ_THR}, log2FC<-{LFC_THR})\")\nprint(\"=\" * 50)\n\n# ── Save ──────────────────────────────────────────────────────────────────────\nde_sorted = de_results.sort_values(\"padj\")\nde_sorted.to_csv(\"results/tables/DE_results_all.csv\", index=False)\nde_sorted[de_sorted.direction != \"Not significant\"]     .to_csv(\"results/tables/DE_results_significant.csv\", index=False)\n\nprint(\"\nSaved → results/tables/DE_results_all.csv\")\nprint(\"Saved → results/tables/DE_results_significant.csv\")\ndisplay(de_sorted.head(10))"
  },
  {
   "cell_type": "markdown",
   "id": "d902cec3cffa4510",
   "metadata": {},
   "source": "### 8.1 Volcano Plot"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a3bba9ae204ba0",
   "metadata": {},
   "outputs": [],
   "source": "fig, ax = plt.subplots(figsize=(9, 7))\n\ndir_pal  = {\"Not significant\": \"#AAAAAA\",\n            \"Up-regulated\":    \"#E74C3C\",\n            \"Down-regulated\":  \"#3498DB\"}\ndir_size = {\"Not significant\": 12, \"Up-regulated\": 22, \"Down-regulated\": 22}\ndir_zord = {\"Not significant\":  1, \"Up-regulated\":  5, \"Down-regulated\":  5}\n\nfor direction, df_sub in de_results.groupby(\"direction\"):\n    log_pv = -np.log10(df_sub[\"pvalue\"].clip(lower=1e-300))\n    ax.scatter(df_sub[\"log2FoldChange\"], log_pv,\n               c=dir_pal[direction], s=dir_size[direction],\n               alpha=0.5 if direction == \"Not significant\" else 0.75,\n               zorder=dir_zord[direction],\n               label=f\"{direction} (n={len(df_sub):,})\")\n\n# Label top 20 DEGs\ntop_label = de_results[de_results.direction != \"Not significant\"]                .nsmallest(20, \"padj\")\nfor _, row in top_label.iterrows():\n    if pd.notna(row[\"pvalue\"]) and row[\"pvalue\"] > 0:\n        ax.annotate(row[\"gene\"],\n                    (row[\"log2FoldChange\"], -np.log10(row[\"pvalue\"])),\n                    fontsize=7.5, fontweight=\"bold\", ha=\"center\",\n                    xytext=(0, 5), textcoords=\"offset points\")\n\n# Threshold lines\nax.axvline(-LFC_THR,  color=\"gray\", ls=\"--\", alpha=0.6, lw=1)\nax.axvline( LFC_THR,  color=\"gray\", ls=\"--\", alpha=0.6, lw=1)\nax.axhline(-np.log10(PADJ_THR), color=\"gray\", ls=\"--\", alpha=0.6, lw=1)\n\nax.set_xlabel(\"log₂(Fold Change)\", fontsize=13)\nax.set_ylabel(\"−log₁₀(p-value)\", fontsize=13)\nax.set_title(\"Volcano Plot: Treatment vs Control\", fontsize=14, fontweight=\"bold\")\nax.legend(fontsize=10, loc=\"upper left\")\n\nxlim = ax.get_xlim(); ylim = ax.get_ylim()\nax.text(xlim[1]*0.85, ylim[1]*0.96, f\"↑ {n_up}\", color=\"#E74C3C\",\n        fontsize=12, fontweight=\"bold\", ha=\"center\")\nax.text(xlim[0]*0.85, ylim[1]*0.96, f\"↓ {n_down}\", color=\"#3498DB\",\n        fontsize=12, fontweight=\"bold\", ha=\"center\")\n\nplt.tight_layout()\nplt.savefig(\"results/figures/04_volcano.pdf\", bbox_inches=\"tight\")\nplt.savefig(\"results/figures/04_volcano.png\", bbox_inches=\"tight\", dpi=300)\nplt.show()\nprint(\"Saved → results/figures/04_volcano.pdf/.png\")"
  },
  {
   "cell_type": "markdown",
   "id": "e5055ed3a1824d7d",
   "metadata": {},
   "source": "## 9. Heatmap of Top Differential Genes\n\nHierarchical clustering of log₂-TPM z-scores for the top 25 up- and 25\ndown-regulated genes reveals the expression patterns across samples."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf166cfba0f409a",
   "metadata": {},
   "outputs": [],
   "source": "N_HM = 25   # top N per direction\n\ntop_up   = de_results[de_results.direction==\"Up-regulated\"  ].nsmallest(N_HM, \"padj\")[\"gene\"].tolist()\ntop_down = de_results[de_results.direction==\"Down-regulated\"].nsmallest(N_HM, \"padj\")[\"gene\"].tolist()\nhm_genes = [g for g in top_up + top_down if g in log2_tpm.index]\n\nhm_expr = log2_tpm.loc[hm_genes]\n\n# Z-score across samples\nhm_z = pd.DataFrame(\n    zscore(hm_expr.values, axis=1),\n    index=hm_expr.index, columns=hm_expr.columns,\n)\n\ncol_colors = pd.Series(\n    [COND_COLORS[metadata.loc[s, \"condition\"]] for s in hm_z.columns],\n    index=hm_z.columns,\n)\nrow_colors = pd.Series(\n    [\"#E74C3C\" if g in top_up else \"#3498DB\" for g in hm_genes],\n    index=hm_genes,\n)\n\ng = sns.clustermap(\n    hm_z, col_colors=col_colors, row_colors=row_colors,\n    cmap=\"RdBu_r\", vmin=-3, vmax=3, center=0,\n    figsize=(10, 14), linewidths=0,\n    dendrogram_ratio=(0.1, 0.18),\n    cbar_pos=(0.02, 0.82, 0.03, 0.12),\n    xticklabels=True, yticklabels=True,\n)\ng.ax_heatmap.set_xticklabels(g.ax_heatmap.get_xticklabels(), fontsize=9, rotation=45, ha=\"right\")\ng.ax_heatmap.set_yticklabels(g.ax_heatmap.get_yticklabels(), fontsize=8)\ng.cax.set_ylabel(\"Z-score\", fontsize=9, rotation=90)\ng.fig.suptitle(f\"Top {len(hm_genes)} DEGs — Z-scored log₂-TPM\",\n               y=1.01, fontsize=13, fontweight=\"bold\")\n\n# Legend patches\nleg_kw = dict(bbox_to_anchor=(1.15, -0.02), loc=\"upper right\", fontsize=9)\ng.ax_col_colors.legend(handles=[\n    mpatches.Patch(color=COND_COLORS[\"Control\"],   label=\"Control\"),\n    mpatches.Patch(color=COND_COLORS[\"Treatment\"], label=\"Treatment\"),\n], title=\"Condition\", **leg_kw)\ng.ax_row_colors.legend(handles=[\n    mpatches.Patch(color=\"#E74C3C\", label=\"Up-regulated\"),\n    mpatches.Patch(color=\"#3498DB\", label=\"Down-regulated\"),\n], title=\"Direction\", loc=\"lower right\", bbox_to_anchor=(0, -0.02), fontsize=9)\n\nplt.savefig(\"results/figures/05_heatmap.pdf\", bbox_inches=\"tight\")\nplt.savefig(\"results/figures/05_heatmap.png\", bbox_inches=\"tight\", dpi=300)\nplt.show()\nprint(\"Saved → results/figures/05_heatmap.pdf/.png\")"
  },
  {
   "cell_type": "markdown",
   "id": "c0d9079f2ac24d08",
   "metadata": {},
   "source": "## 10. Boxplots of Top Individual Genes\n\nShow the expression distribution of the most significantly changed genes,\nwith statistical significance annotations."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33abed4ec1154ee6",
   "metadata": {},
   "outputs": [],
   "source": "# Top 5 up + 4 down = 9 panels in a 3×3 grid\nbox_up   = [g for g in de_results[de_results.direction==\"Up-regulated\"  ]\n              .nsmallest(5,\"padj\")[\"gene\"].tolist() if g in log2_tpm.index]\nbox_down = [g for g in de_results[de_results.direction==\"Down-regulated\"]\n              .nsmallest(4,\"padj\")[\"gene\"].tolist() if g in log2_tpm.index]\nbox_genes = (box_up + box_down)[:9]\n\nfig, axes = plt.subplots(3, 3, figsize=(12, 10))\naxes = axes.flatten()\n\nfor i, gene in enumerate(box_genes):\n    ax = axes[i]\n    df_box = pd.DataFrame({\n        \"Condition\" : [metadata.loc[s, \"condition\"] for s in SAMPLES],\n        \"Expression\": [log2_tpm.loc[gene, s] for s in SAMPLES],\n    })\n    sns.boxplot(data=df_box, x=\"Condition\", y=\"Expression\",\n                palette=COND_COLORS, order=[\"Control\",\"Treatment\"],\n                width=0.5, flierprops={\"marker\":\"o\",\"markersize\":4}, ax=ax)\n    sns.stripplot(data=df_box, x=\"Condition\", y=\"Expression\",\n                  palette=COND_COLORS, order=[\"Control\",\"Treatment\"],\n                  size=6, jitter=0.12, alpha=0.85,\n                  edgecolor=\"white\", linewidth=0.5, ax=ax)\n\n    row = de_results[de_results.gene==gene]\n    if not row.empty:\n        lfc   = row[\"log2FoldChange\"].values[0]\n        padj  = row[\"padj\"].values[0]\n        dirn  = row[\"direction\"].values[0]\n        sig   = \"***\" if padj<0.001 else \"**\" if padj<0.01 else \"*\" if padj<0.05 else \"ns\"\n        ymax  = df_box[\"Expression\"].max()\n        ax.text(0.5, 1.01, sig, transform=ax.transAxes,\n                ha=\"center\", fontsize=14 if sig!=\"ns\" else 10, fontweight=\"bold\")\n        color = \"#E74C3C\" if dirn==\"Up-regulated\" else \"#3498DB\"\n        ax.set_title(f\"{gene}\nlog₂FC={lfc:+.2f}, FDR={padj:.1e}\",\n                     fontsize=9, fontweight=\"bold\", color=color, pad=14)\n    ax.set_xlabel(\"\")\n    ax.set_ylabel(\"log₂(TPM+1)\" if i%3==0 else \"\", fontsize=9)\n\nfor i in range(len(box_genes), len(axes)):\n    axes[i].set_visible(False)\n\nplt.suptitle(\"Top Differentially Expressed Genes\", fontsize=13, fontweight=\"bold\", y=1.01)\nplt.tight_layout()\nplt.savefig(\"results/figures/06_boxplots.pdf\", bbox_inches=\"tight\")\nplt.savefig(\"results/figures/06_boxplots.png\", bbox_inches=\"tight\", dpi=300)\nplt.show()\nprint(\"Saved → results/figures/06_boxplots.pdf/.png\")"
  },
  {
   "cell_type": "markdown",
   "id": "dbe32d192bb646d3",
   "metadata": {},
   "source": "## 11. Pathway Enrichment — Over-Representation Analysis (ORA)\n\nUses the **Enrichr** API (via gseapy) to ask: *are genes in my DEG list\nover-represented in known pathways?*\n\n**Tested databases:** KEGG 2021, GO Biological Process 2021, Reactome 2022"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1543c669dcb54a99",
   "metadata": {},
   "outputs": [],
   "source": "try:\n    import gseapy as gp\n    HAVE_GSEAPY = True\n    print(f\"gseapy {gp.__version__} available.\")\nexcept ImportError:\n    HAVE_GSEAPY = False\n    print(\"gseapy not found. Install: pip install gseapy\")\n    print(\"Sections 11 and 12 require internet access.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73099d82df1c40a8",
   "metadata": {},
   "outputs": [],
   "source": "GENE_SETS_ORA = [\"KEGG_2021_Human\", \"GO_Biological_Process_2021\", \"Reactome_2022\"]\n\n# Use only real HGNC symbols (exclude ENSG placeholders)\ndef real_symbols(gene_list):\n    return [g for g in gene_list if not g.startswith(\"ENSG\")]\n\nif HAVE_GSEAPY:\n    up_genes   = real_symbols(de_results[de_results.direction==\"Up-regulated\"  ][\"gene\"].tolist())\n    down_genes = real_symbols(de_results[de_results.direction==\"Down-regulated\"][\"gene\"].tolist())\n\n    print(f\"ORA input — Up: {len(up_genes)} genes | Down: {len(down_genes)} genes\")\n    print(\"Querying Enrichr (requires internet) …\")\n\n    ora_parts = []\n    for direction, glist in [(\"Up-regulated\", up_genes), (\"Down-regulated\", down_genes)]:\n        if not glist:\n            continue\n        try:\n            enr = gp.enrichr(gene_list=glist, gene_sets=GENE_SETS_ORA,\n                              organism=\"Human\", outdir=None, no_plot=True, cutoff=0.1)\n            df  = enr.results.copy()\n            df[\"Direction\"] = direction\n            ora_parts.append(df)\n        except Exception as e:\n            print(f\"  {direction} ORA failed: {e}\")\n\n    if ora_parts:\n        ora_df = pd.concat(ora_parts, ignore_index=True)\n        ora_df = ora_df[ora_df[\"Adjusted P-value\"] < 0.05]\n        ora_df.to_csv(\"results/tables/ORA_pathway_enrichment.csv\", index=False)\n        print(f\"Significant terms (FDR<0.05): {len(ora_df)}\")\n    else:\n        print(\"No ORA results.\")\n        ora_df = pd.DataFrame()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e185f7a5894685",
   "metadata": {},
   "outputs": [],
   "source": "# ── ORA dot plot ──────────────────────────────────────────────────────────────\nif HAVE_GSEAPY and \"ora_df\" in dir() and len(ora_df) > 0:\n\n    top_terms = []\n    for db in GENE_SETS_ORA:\n        for dirn in [\"Up-regulated\", \"Down-regulated\"]:\n            sub = ora_df[(ora_df.Gene_set==db) & (ora_df.Direction==dirn)].head(6)\n            top_terms.append(sub)\n    plot_df = pd.concat(top_terms).drop_duplicates(\"Term\").reset_index(drop=True)\n    plot_df[\"-log10FDR\"] = -np.log10(plot_df[\"Adjusted P-value\"].clip(1e-50))\n    plot_df[\"GeneRatio\"] = plot_df[\"Overlap\"].apply(\n        lambda x: int(x.split(\"/\")[0]) / max(int(x.split(\"/\")[1]), 1) if \"/\" in str(x) else 0)\n    plot_df[\"Term_short\"] = plot_df[\"Term\"].str[:55]\n    plot_df = plot_df.sort_values([\"Direction\", \"-log10FDR\"], ascending=[True, False])\n\n    fig, ax = plt.subplots(figsize=(11, max(6, len(plot_df)*0.38)))\n    ax.scatter(\n        plot_df[\"-log10FDR\"],\n        range(len(plot_df)),\n        c=plot_df[\"Direction\"].map({\"Up-regulated\":\"#E74C3C\",\"Down-regulated\":\"#3498DB\"}),\n        s=plot_df[\"GeneRatio\"]*600,\n        alpha=0.85, edgecolors=\"white\", linewidth=0.5,\n    )\n    ax.set_yticks(range(len(plot_df)))\n    ax.set_yticklabels(plot_df[\"Term_short\"], fontsize=8)\n    ax.axvline(-np.log10(0.05), color=\"gray\", ls=\"--\", alpha=0.6, lw=1, label=\"FDR=0.05\")\n    ax.set_xlabel(\"−log₁₀(Adjusted P-value)\", fontsize=11)\n    ax.set_title(\"ORA: Pathway Enrichment\", fontsize=13, fontweight=\"bold\")\n    ax.invert_yaxis()\n    ax.grid(axis=\"x\", alpha=0.3)\n    ax.legend(handles=[\n        mpatches.Patch(color=\"#E74C3C\", label=\"Up-regulated genes\"),\n        mpatches.Patch(color=\"#3498DB\", label=\"Down-regulated genes\"),\n    ], fontsize=10)\n\n    plt.tight_layout()\n    plt.savefig(\"results/figures/07_ORA_dotplot.pdf\", bbox_inches=\"tight\")\n    plt.savefig(\"results/figures/07_ORA_dotplot.png\", bbox_inches=\"tight\", dpi=300)\n    plt.show()\n    print(\"Saved → results/figures/07_ORA_dotplot.pdf/.png\")"
  },
  {
   "cell_type": "markdown",
   "id": "a580fcc420264219",
   "metadata": {},
   "source": "## 12. Gene Set Enrichment Analysis (GSEA)\n\nUnlike ORA, GSEA uses **all** tested genes ranked by a continuous metric\n(`−log₁₀(p-value) × sign(log₂FC)`), so it is not limited to a binary DEG cutoff.\n\n> Use `permutation_num=1000` for publication-quality results.\n> We use 100 here for speed."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b33ad1a6dea47c2",
   "metadata": {},
   "outputs": [],
   "source": "if HAVE_GSEAPY:\n    # Build ranked list (all genes, real symbols preferred at top)\n    de_sym = de_results[~de_results.gene.str.startswith(\"ENSG\")].copy()\n    de_sym[\"rank_metric\"] = (\n        -np.log10(de_sym[\"pvalue\"].clip(lower=1e-300)) *\n        np.sign(de_sym[\"log2FoldChange\"])\n    )\n    ranking = (de_sym.dropna(subset=[\"rank_metric\"])\n                     .sort_values(\"rank_metric\", ascending=False)\n                     .set_index(\"gene\")[\"rank_metric\"])\n\n    print(f\"Ranked gene list: {len(ranking):,} genes\")\n    print(f\"  Max rank score : {ranking.max():.1f}\")\n    print(f\"  Min rank score : {ranking.min():.1f}\")\n\n    print(\"Running GSEA prerank (requires internet) …\")\n    try:\n        gsea_res = gp.prerank(\n            rnk            = ranking,\n            gene_sets      = [\"KEGG_2021_Human\", \"Hallmark_2020\"],\n            outdir         = None,\n            min_size       = 15,\n            max_size       = 500,\n            permutation_num= 100,\n            seed           = 42,\n            no_plot        = True,\n            verbose        = False,\n        )\n        gsea_df = gsea_res.res2d.copy()\n        gsea_df = gsea_df[gsea_df[\"FDR q-val\"] < 0.25].sort_values(\"NES\", ascending=False)\n        gsea_df.to_csv(\"results/tables/GSEA_results.csv\", index=False)\n        print(f\"Significant gene sets (FDR<0.25): {len(gsea_df)}\")\n        display(gsea_df.head(10))\n    except Exception as e:\n        print(f\"GSEA failed: {e}\")\n        gsea_df = pd.DataFrame()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54468624e91469a",
   "metadata": {},
   "outputs": [],
   "source": "# ── GSEA bar plot (NES) ───────────────────────────────────────────────────────\nif HAVE_GSEAPY and \"gsea_df\" in dir() and len(gsea_df) > 0:\n\n    top_gsea = pd.concat([\n        gsea_df[gsea_df.NES > 0].head(10),\n        gsea_df[gsea_df.NES < 0].tail(10),\n    ]).reset_index(drop=True)\n    top_gsea[\"Term_short\"] = top_gsea[\"Term\"].str[:60]\n    top_gsea = top_gsea.sort_values(\"NES\")\n\n    fig, ax = plt.subplots(figsize=(10, max(5, len(top_gsea)*0.38)))\n    colors = [\"#3498DB\" if n < 0 else \"#E74C3C\" for n in top_gsea[\"NES\"]]\n    ax.barh(top_gsea[\"Term_short\"], top_gsea[\"NES\"],\n            color=colors, edgecolor=\"white\", linewidth=0.4)\n    ax.axvline(0, color=\"black\", lw=0.8)\n    ax.set_xlabel(\"Normalised Enrichment Score (NES)\", fontsize=11)\n    ax.set_title(\"GSEA: Gene Set Enrichment Analysis\", fontsize=13, fontweight=\"bold\")\n    ax.legend(handles=[\n        mpatches.Patch(color=\"#E74C3C\", label=\"Enriched in Treatment\"),\n        mpatches.Patch(color=\"#3498DB\", label=\"Enriched in Control\"),\n    ], fontsize=10)\n\n    plt.tight_layout()\n    plt.savefig(\"results/figures/08_GSEA_barplot.pdf\", bbox_inches=\"tight\")\n    plt.savefig(\"results/figures/08_GSEA_barplot.png\", bbox_inches=\"tight\", dpi=300)\n    plt.show()\n    print(\"Saved → results/figures/08_GSEA_barplot.pdf/.png\")"
  },
  {
   "cell_type": "markdown",
   "id": "4b3c9028bb42495f",
   "metadata": {},
   "source": "## 13. Gene–Gene Interaction Network (STRING)\n\nQuery the **STRING** protein interaction database for all significant DEGs,\nthen visualise the interaction network with genes coloured by expression direction.\nHub genes (high degree centrality) are candidate master regulators."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412c564c6d9448a9",
   "metadata": {},
   "outputs": [],
   "source": "def query_string(gene_list, species=9606, min_score=400, max_genes=100):\n    \"\"\"\n    Retrieve protein–protein interactions from STRING v12.\n\n    Parameters\n    ----------\n    gene_list  : list of HGNC gene symbols\n    species    : NCBI taxonomy ID (9606 = Homo sapiens)\n    min_score  : combined interaction score threshold (0–1000)\n    max_genes  : cap on query size\n\n    Returns\n    -------\n    pd.DataFrame with columns gene1, gene2, score (0–1)\n    \"\"\"\n    url    = \"https://string-db.org/api/json/network\"\n    params = {\n        \"identifiers\"   : \"%0d\".join(gene_list[:max_genes]),\n        \"species\"       : species,\n        \"required_score\": min_score,\n        \"caller_identity\": \"rnaseq_tutorial\",\n    }\n    try:\n        r = requests.post(url, data=params, timeout=30)\n        r.raise_for_status()\n        data = r.json()\n        if not data:\n            return pd.DataFrame()\n        df = pd.DataFrame(data)[[\"preferredName_A\", \"preferredName_B\", \"score\"]]\n        df.columns = [\"gene1\", \"gene2\", \"score\"]\n        df[\"score\"] = df[\"score\"].astype(float) / 1000     # normalise to 0–1\n        df = df[df.gene1 != df.gene2]\n        return df\n    except Exception as e:\n        print(f\"STRING query failed: {e}\")\n        return pd.DataFrame()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51508f7d0b19436d",
   "metadata": {},
   "outputs": [],
   "source": "sig_genes_real = real_symbols(\n    de_results[de_results.direction != \"Not significant\"][\"gene\"].tolist())\n\nprint(f\"Querying STRING for {len(sig_genes_real)} DEGs (requires internet) …\")\ninteractions = query_string(sig_genes_real, min_score=400)\n\nif interactions.empty:\n    print(\"No interactions returned — using curated fallback network.\")\n    interactions = pd.DataFrame({\n        \"gene1\": [\"CDK1\",\"CDK1\",\"CDK2\",\"CCNB1\",\"PLK1\",\"AURKB\",\"TOP2A\",\n                  \"TP53\",\"CDKN1A\",\"BAX\",\"CASP3\",\"CASP9\",\"STAT1\",\"IRF1\",\n                  \"TNF\",\"NFKB1\",\"IL6\",\"MYC\",\"E2F1\",\"BCL2\"],\n        \"gene2\": [\"CCNB1\",\"PCNA\",\"CCNE1\",\"CDK1\",\"CDK1\",\"CDK1\",\"BIRC5\",\n                  \"CDKN1A\",\"CDK2\",\"BCL2\",\"CASP9\",\"CYCS\",\"IRF1\",\"ISG15\",\n                  \"NFKB1\",\"RELA\",\"STAT3\",\"CDK4\",\"CCND1\",\"MCL1\"],\n        \"score\": [0.97,0.89,0.94,0.97,0.92,0.88,0.87,\n                  0.98,0.96,0.92,0.95,0.91,0.93,0.90,\n                  0.86,0.94,0.89,0.88,0.91,0.87],\n    })\n    print(f\"Fallback: {len(interactions)} interactions loaded.\")\nelse:\n    print(f\"Retrieved {len(interactions)} interactions among \"\n          f\"{len(set(interactions.gene1)|set(interactions.gene2))} genes.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fd55577bfe496a",
   "metadata": {},
   "outputs": [],
   "source": "# ── Build networkx graph ──────────────────────────────────────────────────────\nG = nx.Graph()\nfor _, row in interactions.iterrows():\n    G.add_edge(row.gene1, row.gene2, weight=row.score)\n\n# Attach DE metadata to nodes\ndir_map   = de_results.set_index(\"gene\")[\"direction\"].to_dict()\nlfc_map   = de_results.set_index(\"gene\")[\"log2FoldChange\"].to_dict()\n\nfor node in G.nodes():\n    G.nodes[node][\"direction\"] = dir_map.get(node, \"Not significant\")\n    G.nodes[node][\"lfc\"]       = lfc_map.get(node, 0.0)\n\n# Restrict to largest connected component\nlargest_cc = max(nx.connected_components(G), key=len)\nG_main     = G.subgraph(largest_cc).copy()\n\ndeg_cent = nx.degree_centrality(G_main)\nbtw_cent = nx.betweenness_centrality(G_main)\n\nprint(f\"Network  — nodes: {G.number_of_nodes()}, edges: {G.number_of_edges()}\")\nprint(f\"Largest CC — nodes: {G_main.number_of_nodes()}, edges: {G_main.number_of_edges()}\")\nprint()\nprint(\"Top 10 hub genes (degree centrality):\")\nfor gene, cent in sorted(deg_cent.items(), key=lambda x: -x[1])[:10]:\n    dirn = G_main.nodes[gene][\"direction\"]\n    print(f\"  {gene:<12} {cent:.3f}  [{dirn}]\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511bbc06ab27436e",
   "metadata": {},
   "outputs": [],
   "source": "node_pal = {\"Up-regulated\": \"#E74C3C\", \"Down-regulated\": \"#3498DB\",\n            \"Not significant\": \"#AAAAAA\"}\n\nfig, axes = plt.subplots(1, 2, figsize=(18, 8))\n\n# ── Network layout ────────────────────────────────────────────────────────────\npos   = nx.spring_layout(G_main,\n                         k=2.5/np.sqrt(G_main.number_of_nodes()),\n                         seed=42, iterations=120)\nncolors = [node_pal[G_main.nodes[n][\"direction\"]] for n in G_main.nodes()]\nnsizes  = [350 + deg_cent[n]*4000 for n in G_main.nodes()]\newidths = [G_main[u][v][\"weight\"]*3 for u, v in G_main.edges()]\n\nnx.draw_networkx_edges(G_main, pos, ax=axes[0], alpha=0.35,\n                       width=ewidths, edge_color=\"gray\")\nnx.draw_networkx_nodes(G_main, pos, ax=axes[0],\n                       node_color=ncolors, node_size=nsizes,\n                       alpha=0.9, edgecolors=\"white\", linewidths=1)\n# Label high-degree nodes\ntop50pct = np.percentile(list(deg_cent.values()), 50)\nnx.draw_networkx_labels(G_main, pos,\n    labels={n: n for n in G_main.nodes() if deg_cent[n] >= top50pct},\n    font_size=7.5, font_weight=\"bold\", ax=axes[0])\n\naxes[0].set_title(\"Gene Interaction Network (STRING)\", fontsize=13, fontweight=\"bold\")\naxes[0].axis(\"off\")\naxes[0].legend(handles=[\n    mpatches.Patch(color=c, label=d)\n    for d, c in node_pal.items()\n], fontsize=10, loc=\"lower left\")\n\n# ── Top hub genes bar chart ───────────────────────────────────────────────────\nhub_df = (pd.DataFrame({\"Gene\": list(deg_cent.keys()),\n                         \"Degree Centrality\": list(deg_cent.values())})\n            .sort_values(\"Degree Centrality\", ascending=False)\n            .head(15)\n            .reset_index(drop=True))\nhub_df[\"Direction\"] = hub_df[\"Gene\"].map(\n    lambda g: G_main.nodes[g][\"direction\"] if g in G_main.nodes() else \"Not significant\")\nhub_colors = hub_df[\"Direction\"].map(node_pal).values\n\naxes[1].barh(hub_df[\"Gene\"][::-1], hub_df[\"Degree Centrality\"][::-1],\n             color=hub_colors[::-1], edgecolor=\"white\", linewidth=0.5)\naxes[1].set_xlabel(\"Degree Centrality\", fontsize=11)\naxes[1].set_title(\"Top Hub Genes\", fontsize=13, fontweight=\"bold\")\n\nplt.tight_layout()\nplt.savefig(\"results/figures/09_gene_network.pdf\", bbox_inches=\"tight\")\nplt.savefig(\"results/figures/09_gene_network.png\", bbox_inches=\"tight\", dpi=300)\nplt.show()\nprint(\"Saved → results/figures/09_gene_network.pdf/.png\")"
  },
  {
   "cell_type": "markdown",
   "id": "f12aad80b37e4daa",
   "metadata": {},
   "source": "## 14. Transcription Factor Binding Prediction\n\nTwo complementary approaches:\n\n| Method | Tool | What it asks |\n|--------|------|-------------|\n| **TF Enrichment** | ChEA3 API | Which TFs have targets over-represented among my DEGs? |\n| **TF Activity** | decoupler-py + CollecTRI | Which TFs show differential *activity* across conditions? |\n\n### 14.1 ChEA3 — TF–Target Enrichment\n\nChEA3 integrates ENCODE ChIP-seq, literature ChIP-seq, ARCHS4 co-expression,\nand other resources to rank TFs whose known targets are enriched in a gene list."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601573be63a440fb",
   "metadata": {},
   "outputs": [],
   "source": "CHEA3_URL = \"https://maayanlab.cloud/chea3/api/enrich/\"\n\ndef query_chea3(gene_list: list, query_name: str = \"DEG_query\") -> dict:\n    \"\"\"\n    Submit a gene list to the ChEA3 API.\n\n    Returns\n    -------\n    dict  keyed by library name; each value is a list of TF dicts with\n          fields: TF, Rank, Score, Overlapping_Genes, ...\n    \"\"\"\n    payload = {\"query_name\": query_name, \"gene_set\": gene_list}\n    try:\n        r = requests.post(CHEA3_URL, json=payload, timeout=60)\n        r.raise_for_status()\n        return r.json()\n    except Exception as e:\n        print(f\"ChEA3 query failed: {e}\")\n        return {}\n\n\ndef parse_chea3(result: dict, library: str = \"Integrated--meanRank\",\n                top_n: int = 25) -> pd.DataFrame:\n    \"\"\"\n    Parse ChEA3 JSON into a tidy DataFrame.\n    Tries 'Integrated--meanRank' first, falls back to the first available library.\n    \"\"\"\n    if not result:\n        return pd.DataFrame()\n    if library not in result:\n        library = next(iter(result))\n        print(f\"  Using library: {library}\")\n    rows = result[library][:top_n]\n    df   = pd.DataFrame(rows)\n    df[\"Rank\"]  = pd.to_numeric(df[\"Rank\"],  errors=\"coerce\")\n    df[\"Score\"] = pd.to_numeric(df[\"Score\"], errors=\"coerce\")\n    return df.sort_values(\"Rank\").reset_index(drop=True)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6020d8c5e0b43b8",
   "metadata": {},
   "outputs": [],
   "source": "up_real   = real_symbols(de_results[de_results.direction==\"Up-regulated\"  ][\"gene\"].tolist())\ndown_real = real_symbols(de_results[de_results.direction==\"Down-regulated\"][\"gene\"].tolist())\n\nprint(f\"Querying ChEA3 with {len(up_real)} up and {len(down_real)} down DEGs …\")\n\nchea3_up   = query_chea3(up_real,   \"Upregulated_DEGs\")\nchea3_down = query_chea3(down_real, \"Downregulated_DEGs\")\n\ntf_up   = parse_chea3(chea3_up,   top_n=20)\ntf_down = parse_chea3(chea3_down, top_n=20)\n\nif not tf_up.empty:\n    tf_up[\"Direction\"]   = \"Up-regulated targets\"\nif not tf_down.empty:\n    tf_down[\"Direction\"] = \"Down-regulated targets\"\n\ntf_all = pd.concat([tf_up, tf_down], ignore_index=True)\nif not tf_all.empty:\n    tf_all.to_csv(\"results/tables/ChEA3_TF_enrichment.csv\", index=False)\n    print(\"Saved → results/tables/ChEA3_TF_enrichment.csv\")\n    display(tf_all.head(10))"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7838d27625a4e0b",
   "metadata": {},
   "outputs": [],
   "source": "# ── ChEA3 bar chart ───────────────────────────────────────────────────────────\nif not tf_up.empty or not tf_down.empty:\n\n    fig, axes = plt.subplots(1, 2, figsize=(14, 7))\n\n    for ax, df_tf, title, color in zip(\n        axes,\n        [tf_up.head(15), tf_down.head(15)],\n        [\"TFs enriched in Up-regulated DEGs\",\n         \"TFs enriched in Down-regulated DEGs\"],\n        [\"#E74C3C\", \"#3498DB\"],\n    ):\n        if df_tf.empty:\n            ax.text(0.5, 0.5, \"No results\", ha=\"center\", va=\"center\",\n                    transform=ax.transAxes)\n            ax.set_title(title, fontweight=\"bold\")\n            continue\n\n        df_plot = df_tf.sort_values(\"Score\", ascending=True)\n        ax.barh(df_plot[\"TF\"], df_plot[\"Score\"],\n                color=color, edgecolor=\"white\", linewidth=0.4, alpha=0.85)\n        ax.set_xlabel(\"ChEA3 Score (higher = more enriched)\", fontsize=10)\n        ax.set_title(title, fontsize=11, fontweight=\"bold\")\n        ax.tick_params(labelsize=9)\n\n    plt.suptitle(\"ChEA3: Predicted Upstream Transcription Factors\",\n                 fontsize=13, fontweight=\"bold\")\n    plt.tight_layout()\n    plt.savefig(\"results/figures/10a_ChEA3_TF_enrichment.pdf\", bbox_inches=\"tight\")\n    plt.savefig(\"results/figures/10a_ChEA3_TF_enrichment.png\", bbox_inches=\"tight\", dpi=300)\n    plt.show()\n    print(\"Saved → results/figures/10a_ChEA3_TF_enrichment.pdf/.png\")"
  },
  {
   "cell_type": "markdown",
   "id": "9975bd53ca3040c9",
   "metadata": {},
   "source": "### 14.2 TF Activity Inference — decoupler-py + CollecTRI\n\n**CollecTRI** is a manually curated TF–target regulon.\n**decoupler-py** uses a univariate linear model (ULM) to score how much each TF's\ntarget programme is up- or down-regulated in each sample, then compares activities\nacross conditions."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ece3a0c48f47b4",
   "metadata": {},
   "outputs": [],
   "source": "try:\n    import decoupler as dc\n    HAVE_DC = True\n    print(f\"decoupler {dc.__version__} available.\")\nexcept ImportError:\n    HAVE_DC = False\n    print(\"decoupler not found. Install: pip install decoupler\")\n    print(\"Section 14.2 will be skipped.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2b6f9a0e724ab8",
   "metadata": {},
   "outputs": [],
   "source": "if HAVE_DC:\n    print(\"Downloading CollecTRI regulon …\")\n    try:\n        regulon = dc.get_collectri(organism=\"human\", split_complexes=False)\n        print(f\"  {len(regulon):,} TF–target interactions, \"\n              f\"{regulon['source'].nunique()} TFs\")\n\n        # log2-TPM matrix: genes × samples\n        mat = np.log2(tpm_filt + 1)\n\n        print(\"Inferring TF activities with ULM …\")\n        acts, pvals = dc.run_ulm(\n            mat     = mat.T,         # samples × genes\n            net     = regulon,\n            source  = \"source\",\n            target  = \"target\",\n            weight  = \"weight\",\n            verbose = False,\n        )\n\n        # Differential TF activity: t-test Control vs Treatment\n        ctrl_s = [s for s in SAMPLES if metadata.loc[s,\"condition\"]==\"Control\"]\n        trt_s  = [s for s in SAMPLES if metadata.loc[s,\"condition\"]==\"Treatment\"]\n\n        tf_stats = []\n        for tf in acts.columns:\n            c_vals = acts.loc[ctrl_s, tf].values\n            t_vals = acts.loc[trt_s,  tf].values\n            t_stat, pv = stats.ttest_ind(t_vals, c_vals, equal_var=False)\n            mean_diff  = t_vals.mean() - c_vals.mean()\n            tf_stats.append({\"TF\": tf, \"mean_diff\": mean_diff,\n                              \"t_stat\": t_stat, \"pvalue\": pv})\n\n        tf_act_df = pd.DataFrame(tf_stats)\n        from statsmodels.stats.multitest import multipletests\n        _, tf_act_df[\"padj\"], *_ = multipletests(\n            tf_act_df[\"pvalue\"].fillna(1), method=\"fdr_bh\")\n        tf_act_df = tf_act_df.sort_values(\"padj\")\n        tf_act_df.to_csv(\"results/tables/TF_activity_decoupler.csv\", index=False)\n\n        print(f\"Saved → results/tables/TF_activity_decoupler.csv\")\n        sig_tfs = tf_act_df[tf_act_df.padj < 0.05]\n        print(f\"Significantly differential TFs (FDR<0.05): {len(sig_tfs)}\")\n        display(tf_act_df.head(15))\n\n    except Exception as e:\n        print(f\"decoupler analysis failed: {e}\")\n        tf_act_df = pd.DataFrame()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbdfafe276c4db0",
   "metadata": {},
   "outputs": [],
   "source": "# ── TF activity heatmap ───────────────────────────────────────────────────────\nif HAVE_DC and \"acts\" in dir() and len(acts) > 0 and \"tf_act_df\" in dir()         and len(tf_act_df) > 0:\n\n    top_tf_act = tf_act_df.nsmallest(30, \"padj\")[\"TF\"].tolist()\n    top_tf_act = [t for t in top_tf_act if t in acts.columns]\n\n    act_hm = acts[top_tf_act].T   # TFs × samples\n\n    col_colors = pd.Series(\n        [COND_COLORS[metadata.loc[s, \"condition\"]] for s in act_hm.columns],\n        index=act_hm.columns)\n\n    act_hm_z = pd.DataFrame(\n        zscore(act_hm.values, axis=1),\n        index=act_hm.index, columns=act_hm.columns)\n\n    g = sns.clustermap(\n        act_hm_z, col_colors=col_colors,\n        cmap=\"RdBu_r\", vmin=-2, vmax=2, center=0,\n        figsize=(9, 10), linewidths=0, yticklabels=True,\n        dendrogram_ratio=(0.1, 0.15),\n        cbar_pos=(0.02, 0.82, 0.03, 0.12),\n    )\n    g.ax_heatmap.set_yticklabels(g.ax_heatmap.get_yticklabels(), fontsize=8)\n    g.ax_heatmap.set_xticklabels(g.ax_heatmap.get_xticklabels(), fontsize=9,\n                                  rotation=45, ha=\"right\")\n    g.cax.set_ylabel(\"Z-score\", fontsize=9)\n    g.fig.suptitle(\"TF Activity (decoupler ULM + CollecTRI)\nZ-scored across samples\",\n                   y=1.01, fontsize=12, fontweight=\"bold\")\n    g.ax_col_colors.legend(handles=[\n        mpatches.Patch(color=COND_COLORS[\"Control\"],   label=\"Control\"),\n        mpatches.Patch(color=COND_COLORS[\"Treatment\"], label=\"Treatment\"),\n    ], loc=\"upper right\", bbox_to_anchor=(1.4, 0), fontsize=9)\n\n    plt.savefig(\"results/figures/10b_TF_activity_heatmap.pdf\", bbox_inches=\"tight\")\n    plt.savefig(\"results/figures/10b_TF_activity_heatmap.png\", bbox_inches=\"tight\", dpi=300)\n    plt.show()\n    print(\"Saved → results/figures/10b_TF_activity_heatmap.pdf/.png\")"
  },
  {
   "cell_type": "markdown",
   "id": "856dd2ac12ec4cdd",
   "metadata": {},
   "source": "## 15. Summary\n\n### Pipeline complete ✓\n\n| Output file | Contents |\n|------------|---------|\n| `results/tables/DE_results_all.csv` | All tested genes with log₂FC, p-value, FDR |\n| `results/tables/DE_results_significant.csv` | Significant DEGs only |\n| `results/tables/ORA_pathway_enrichment.csv` | ORA enrichment results |\n| `results/tables/GSEA_results.csv` | GSEA prerank results |\n| `results/tables/ChEA3_TF_enrichment.csv` | TF enrichment (ChEA3) |\n| `results/tables/TF_activity_decoupler.csv` | Differential TF activity |\n| `results/figures/01_qc_summary` | Library sizes, gene detection, sample correlation |\n| `results/figures/02_normalization` | Raw vs TPM count distributions |\n| `results/figures/03_pca` | PCA plots coloured by condition and batch |\n| `results/figures/04_volcano` | Volcano plot |\n| `results/figures/05_heatmap` | Clustered heatmap of top DEGs |\n| `results/figures/06_boxplots` | Boxplots of top individual genes |\n| `results/figures/07_ORA_dotplot` | ORA pathway dotplot |\n| `results/figures/08_GSEA_barplot` | GSEA NES barplot |\n| `results/figures/09_gene_network` | STRING gene interaction network |\n| `results/figures/10a_ChEA3_TF_enrichment` | ChEA3 TF bar charts |\n| `results/figures/10b_TF_activity_heatmap` | TF activity heatmap |\n\n### Next steps\n- Validate top DEGs with qPCR or orthogonal data\n- Overlay TF binding sites with ATAC-seq / ChIP-seq peaks\n- Run multi-contrast or time-course DE analysis\n- Integrate with proteomics or single-cell RNA-seq data"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30316d7afc04a36",
   "metadata": {},
   "outputs": [],
   "source": "print(\"=\" * 60)\nprint(\"  OUTPUT SUMMARY\")\nprint(\"=\" * 60)\nup_n   = (de_results.direction==\"Up-regulated\").sum()\ndown_n = (de_results.direction==\"Down-regulated\").sum()\nprint(f\"  Samples          : {N_SAMPLES} ({', '.join(metadata.condition.value_counts().to_dict().keys())})\")\nprint(f\"  Genes analysed   : {counts_filt.shape[0]:,}\")\nprint(f\"  Up-regulated DEGs: {up_n}\")\nprint(f\"  Down-regulated   : {down_n}\")\nprint(\"=\" * 60)\nprint()\nprint(\"Results saved to:\")\nfor f in sorted(\n    [os.path.join(r, f) for r, _, fs in os.walk(\"results\") for f in fs\n     if f.endswith((\".csv\",\".pdf\",\".png\"))]\n):\n    print(f\"  {f}\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}